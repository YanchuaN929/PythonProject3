# 性能优化：加载缓存流程冗余分析（基于终端输出@Python 660-1008）

> 目标：在“文件未变化且缓存命中”的常见场景下，进一步降低 **无意义的Excel IO / Registry写入 / 重复UI渲染与过滤**，让“点开始处理”接近“秒开”。
>
> 本文仅做原因分析与优化建议，不直接改动代码逻辑（除非你确认方案后再动手）。

---

## 1. 本次终端输出的关键事实（证据）

在你的日志中同时出现了：

- **并发预加载Excel**（但随后仍走缓存）
  - `🚀 开始并发预加载Excel文件...`
- **缓存命中**
  - `🔍 检查文件标识和缓存...`
  - `✅ 文件未变化，尝试加载缓存...`
  - `✅ 成功加载 26 个缓存结果`
- **随后仍执行“开始批量处理 file1~6”，并对每个项目打印“✅ 使用缓存”**
  - `开始批量处理文件1类型，共 7 个文件`
  - `✅ 使用缓存: 项目1907file1 (37行)`（大量类似行）
- **UI层超期/显示过滤重复出现多次**
  - ` [超期过滤] 文件2: 隐藏287个超期>30工作日的任务 (337→50行)` 出现不止一次
  - ` [超期过滤] 文件3: 隐藏4个超期>30工作日的任务 (48→44行)` 出现不止一次
  - `外部需打开接口 - 按接口时间列排序（降序）` 也重复

**结论**：在“缓存已加载+文件未变化”的场景里，当前流程仍然执行了多段本可跳过的工作。

---

## 2. 终端输出对应到代码的调用链（定位）

结合 `base.py` 的实现，本次流程大致是：

1. `refresh_file_list()`（你点击“刷新文件列表”触发）
2. `identify_target_files()`：识别各类型文件
3. `identify_target_files()` **无条件执行并发预加载**（方案3）
   - 位置：`base.py` 里 `identify_target_files` 末尾有 `print("\n🚀 开始并发预加载Excel文件...")`
4. `refresh_file_list()` 内部调用 `_check_and_load_cache()`
   - 位置：`base.py::_check_and_load_cache` 打印 `🔍 检查文件标识和缓存...`
   - 行为：对 file1~6 逐个项目 `load_cached_result(...)`，并把结果写入 `processing_results_multiX`
5. 你随后点击 “开始处理” -> `start_processing()`
6. `start_processing()` 内部开启后台线程 `process_files()`，对 file1~6 做“批量处理”
   - 关键点：每个 fileX 批量处理开头会 **清空 `self.processing_results_multiX = {}`**
   - 然后再次调用 `_process_with_cache(...)`，又会 `load_cached_result(...)` 一遍（缓存命中打印“✅ 使用缓存”）
7. 处理结束后 `update_display()`：
   - **无条件**调用 `registry_hooks.on_scan_finalize(...)`
   - 对每个 resultsX 调用 `display_resultsX(...)`（渲染+过滤）
   - `notebook.select(active_tab)` 触发 `on_tab_changed`，**可能再次触发 display_resultsX**，导致过滤/排序重复打印

### 2.1 你提出的问题1：`identify_target_files()` 的并发预加载是否关联“主显示窗”？

**有直接关联，但仅影响“未开始处理/未有处理结果时”的原始预览显示，不影响“处理结果显示”。**

证据（来自 `base.py::on_tab_changed` 的显示分支，逻辑是“优先处理结果，否则原始预览”）：

- 当某个 tab 对应类型 **没有已处理结果** 时（`has_processed_resultsX == False`）：
  - 若 `self.fileX_data` 已经存在（由并发预加载或 `load_file_to_viewer()` 读入），会走 `display_excel_data(viewer, self.fileX_data, tab_name)` 展示 **原始数据预览**；
  - 否则才会走 `load_file_to_viewer(self.target_fileX, ...)` 现读现显。

因此：

- **如果我们“完全移除预加载”**：不会影响处理结果的显示，但会让用户在“未处理状态切 tab 查看原始内容”时，首次切换更慢（因为改成按需读取）。
- **更安全的优化方式**是“条件化预加载”：仅在确实需要原始预览时才预加载；或者完全按需读取但保证 `load_file_to_viewer()` 路径稳定。

---

## 3. 明确的“多余逻辑”清单（按收益排序）

### 3.1 冗余1：无条件“并发预加载Excel文件”

**现象**：即使后续缓存已命中（`✅ 成功加载 26 个缓存结果`），仍提前读取了若干Excel（你日志里只显示读完了部分文件，但IO已发生）。

**代码根因**：`identify_target_files()` 末尾的“方案3”块，无条件执行预加载（通常读取每类的第一个文件）。

**为什么多余/有害**：
- 缓存命中时，`start_processing()`主要从 `.pkl` 缓存读结果，不需要这些“预读出来的DataFrame”。
- 网络盘/大Excel时，预加载会抢占IO，拖慢“用户可感知的第一屏响应”。

**优化建议（优先）**：
- **条件化预加载（推荐，兼顾显示体验与速度）**：
  - 仅当“该文件类型在 UI 处于**未处理状态**（`has_processed_resultsX == False`）且用户确实可能看原始预览”时，才预加载该类型的首个文件；
  - 如果 `_check_and_load_cache()` 已经成功加载了该类型的缓存结果（即用户下一步大概率要看处理结果），则 **跳过**该类型的原始预加载。
- **或者改为纯按需加载（更极致的速度，稍影响体验）**：
  - 不预加载，用户切 tab 时由 `load_file_to_viewer()` 现读现显。

> 安全性说明：无论采用哪种，只要保留 `load_file_to_viewer()` 分支，**不会影响处理结果显示**；影响的只是“未处理时看原始预览”的响应方式。

---

### 3.2 冗余2：“刷新阶段已加载缓存” + “开始处理阶段再次加载缓存”

**现象**：你日志里先 `✅ 成功加载 26 个缓存结果`，然后又进入 `开始批量处理文件1类型...` 并对每个项目打印 `✅ 使用缓存...`。

**代码根因**：
- `_check_and_load_cache()` 已经把缓存结果放进 `processing_results_multiX`；
- 但 `start_processing()` 在每个 fileX 开头又把 `self.processing_results_multiX = {}` 重置掉，并重新 `_process_with_cache()`。

**为什么多余**：
- 在“文件未变化+缓存命中”场景，二次 `load_cached_result` 纯粹重复IO（虽然比读Excel快，但仍是磁盘IO+反序列化开销）。

**优化建议（高收益）**：
给 `start_processing()` 增加一个“缓存复用快路径”：
- 条件（关键：**必须是“按文件粒度”判定变化**，不是全局一刀切）：
  - 基于 `file_manager.get_changed_files(all_file_paths)` 得到的 `changed_files` 集合；对每个 fileX/每个项目对应的 `file_path`：
    - 若该 `file_path` **不在** `changed_files`，则视为“未变化文件”；
    - 若该 `file_path` **在** `changed_files`，则该文件仍需走原流程（清缓存/重处理/写Registry，取决于你的业务约束）。
  - 且本轮在 `refresh_file_list()->_check_and_load_cache()` 已经成功加载过缓存（最好记录一个“缓存加载快照”，例如：时间戳 + all_file_paths 指纹 + 成功加载数量）。
  - 且当前 fileX 对应的 `processing_results_multiX` 已经存在（避免误跳过导致空窗）。
- 动作：
  - 对“未变化文件”：**跳过** per-project 循环与 `_process_with_cache()`（避免重复 `load_cached_result`）；
  - 对“变化文件”或“缓存缺失文件”（某些项目缓存不存在、会触发真实读Excel的情况）：只处理这些目标（增量处理）。

这样“刷新->开始处理”就不会重复读缓存。

> 安全性说明：这条优化的关键是“只跳过未变化且已有结果的部分”，因此不会影响显示；相反，它会减少你日志里大量的 `✅ 使用缓存: 项目...` 重复出现。

---

### 3.3 冗余3：缓存命中也做 Registry 全量 on_process_done + on_scan_finalize

**现象**：大量
- `[INFO] Registry: 文件X项目YYYY写入N个任务`
- 以及 `scan_finalize: batch=...`

即使你本次是“文件未变化 + 使用缓存”。

**代码根因**：
`start_processing()` 的批量处理对每个 fileX 都：
- 构建 `raw_results_for_registry`
- `registry_hooks.on_process_done(...)`
并且 `update_display()` 无条件 `on_scan_finalize(...)`。

**为什么可能是多余**：
如果源Excel未变化，Registry 上次扫描结果理论上仍有效；
重复写入 + finalize 在网络盘/SQLite 上会引入锁竞争、IO、以及大量业务判断（你日志里 file2 有大量“预期时间变化，重置状态”的输出）。

**你给出的业务约束（已确认）**：

- 当“源Excel未变化”时，本次运行 **允许不触发任何 registry 写入与 finalize**；
- `missing` 归档（`scan_finalize`）的频率：**只有当“管理员角色”运行开始处理时才执行**。

基于此，优化建议需要改成更严格、更安全的版本：

- **Registry on_process_done：按文件/按项目增量触发**
  - 仅对满足任一条件的项目调用：
    - 该项目对应 `file_path` 在 `changed_files` 中（源Excel确实变化）；
    - 或该项目本次发生了“缓存未命中 -> 实际读取Excel并重新计算”（即真实新鲜结果），避免 Registry 长期不更新。
  - 对于“缓存命中 + 文件未变化”的项目：跳过 `on_process_done`（纯重复写入，且你已允许跳过）。

- **Registry on_scan_finalize：角色门禁**
  - 仅当 `("管理员" in user_roles)` 且（本轮确实做过增量 `on_process_done` 或检测到 `changed_files` 非空）时才执行；
  - 非管理员运行：即使开始处理，也 **不执行 finalize**（符合你给出的频率要求）。

> 这条优化对速度提升很大，但涉及“Registry是否必须每次运行都刷新”的业务约束，需要你确认期望一致性（例如：是否依赖每次运行来清理missing/归档）。

#### 3.3.1 你提出的问题3：会不会影响“新增的显示缓存/显示逻辑”？

需要分两类依赖看：

- **显示缓存本身（`.pkl` + `processing_results_multiX`）**：
  - 它来自 `file_manager.load_cached_result(...)` 与内存字典，**不依赖 Registry**。
  - 因此“跳过 Registry 写入/finalize”不会让“缓存显示”失效。

- **显示过滤中“查询Registry状态”的部分**（例如“待审查/待确认过滤”、“超期过滤”等）：
  - 这些过滤逻辑通常是在 `display_resultsX` 中查询 registry 任务状态以决定是否展示/隐藏；
  - 在你确认的规则下：
    - 源Excel未变化时跳过写入：Registry 中的状态仍是“上一次扫描的稳定状态”，显示不会崩；
    - missing 归档只在管理员执行：非管理员看到的“missing清理”可能**不及时**（但这是你明确接受的业务策略）。

结论：**对显示安全**，但需要在文档中明确“非管理员不做missing归档带来的可见性差异”，避免误解。

---

### 3.4 冗余4：UI过滤/渲染多次触发（超期过滤日志重复）

**现象**：
同一个 file2/file3 的
- `[超期过滤] ...`
- `[显示过滤] ...`
在一次运行尾部重复出现多次；以及排序日志重复。

**代码根因（组合效应）**：
1) `update_display()` 对每个 fileX 都调用一次 `display_resultsX(...)`；
2) `update_display()` 末尾 `notebook.select(active_tab)` 会触发 `<<NotebookTabChanged>>` -> `on_tab_changed()`；
3) `on_tab_changed()` 又会再次调用 `display_results2/3/4/5/6`（至少对当前tab），导致过滤/排序重复；
4) 某些显示路径还会再触发 `refresh_current_tab_display()`（在刷新文件列表完成后也会调用）。

**优化建议（中高收益，风险低）**：
让“处理完成后的渲染”只发生一次：
- 方案A（推荐）：`update_display()` 只渲染 **active_tab**（当前要看的那一页），其他 tab 等用户切换时再渲染
- 方案B：在 `notebook.select(active_tab)` 前临时屏蔽 `on_tab_changed`（设置一个 `_suppress_tab_change_render=True` 标志），避免“程序选择tab”导致二次渲染
- 方案C：`update_display()` 不直接调用 `display_resultsX`，只更新状态/数据，然后 `notebook.select(active_tab)` 后让 `on_tab_changed()` 渲染一次即可

此外，“统计弹窗的 display_count”当前通过 `_exclude_pending_confirmation_rows(results.copy(), ...)` 重新跑一遍过滤来计算数量，也属于重复计算；更快的方式是 **复用 display_resultsX 内已经得到的最终显示df** 来计数。

---

## 4. 推荐的落地顺序（最大化收益/最小化风险）

### 第一步（低风险，高收益）
- **移除/条件化** `identify_target_files()` 的无条件预加载（缓存命中时不预读Excel）
- **避免“刷新加载缓存”与“开始处理再次加载缓存”重复**：引入 start_processing 的缓存复用快路径

### 第二步（中风险，最高收益）
- Registry 改为增量更新（按你的业务约束落地）：
  - 只在“文件变更/缓存未命中”时 `on_process_done`
  - `on_scan_finalize` 增加 **管理员角色门禁**（仅管理员开始处理时触发）

### 第三步（低风险，中收益）
- 合并UI渲染路径：避免 `update_display()` 与 `on_tab_changed()` 双重渲染，消除重复超期过滤/排序

---

## 5. 你可以用来验证优化效果的观测指标

建议每次改动后对比以下日志是否消失/减少：
- `🚀 开始并发预加载Excel文件...`（缓存命中场景应消失）
- `✅ 成功加载 XX 个缓存结果` 之后，不应再出现大量 `✅ 使用缓存: 项目...`
- `[INFO] Registry: 文件X项目...写入...` 在“未变化+缓存命中”场景应显著减少或为0（取决于你确认的业务要求）
- `[超期过滤]` / `[显示过滤]` 在一次运行尾部每个文件类型应最多出现一次（或仅在当前tab出现一次）

---

## 6. 下一步需要你确认的两点（决定Registry优化是否可做）

1) **Registry一致性要求**：当“源Excel未变化”时，你是否允许本次运行 **不触发任何 registry 写入与 finalize**？
   - ✅ 你已确认：**允许**
2) **missing归档频率**：`scan_finalize` 是否必须“每次开始处理都执行”，还是可以“仅在源变更后/定时执行”？
   - ✅ 你已确认：**只有当管理员角色运行开始处理时才执行**

你确认后，我可以按“第一步->第二步->第三步”的顺序逐步改代码，并给每一步配一个最小pytest用例锁定行为。

---

## 7. 复核：本文修改建议是否“有效且安全”（再次自检）

结合你最新的终端片段（同一次运行里，部分项目缓存命中、部分项目发生缓存未命中而实际读Excel），可以得出更精确的安全边界：

- **3.2 的“缓存复用快路径”必须支持“部分命中、部分未命中”**：
  - 只跳过“未变化 + 已有结果”的项目；
  - 对“缓存缺失导致真实读Excel”的项目继续处理（否则会漏数据）。

- **3.3 的 Registry 增量策略也必须支持“部分命中、部分未命中”**：
  - 对“真实读Excel得到的新鲜结果”执行 `on_process_done`（即便 `changed_files` 为空，也可能存在缓存缺失/首次运行）；
  - 对“缓存命中且未变化”的部分跳过写入。

- **3.1 的预加载优化不能破坏“未处理时的原始预览体验”**：
  - 必须保留 `load_file_to_viewer()` 的按需读取路径；
  - 若你希望 tab 切换仍然顺滑，则采用“条件化预加载（仅原始预览需要时）”更稳妥。

在上述约束下，三个优化点可以做到：**速度显著提升 + 不影响主显示窗稳定性 + Registry 策略符合你的业务要求**。

---

## 8. 全链路“名称统一/未命中风险”审计（处理→显示→写回→Registry）

> 你担心的“变量/字段名不一致导致未命中（列名 vs 列序号、列字母等）”在当前仓库**确实存在多源表达**。本节先做统一口径审计与风险分级，待你确认后再统一重构（不在本文直接改代码）。

### 8.1 现状：同一概念存在多种表达（高风险源）

- **列定位表达混用**（最常见的未命中根源）
  - **处理侧**：`main.py` 大量使用 `df.iloc[:, 数字]`（0-based 列序号；通常配合 `pd.read_excel(..., header=None)`）
  - **写回侧**：`input_handler.py` 使用 Excel **列字母**（如 `S/M/V`、`BM` 等）+ `openpyxl ws["S{row}"]`
  - **显示/过滤侧**：`window.py` / `registry.util` 多用 **语义列名**（如 `"接口号"`, `"项目号"`, `"接口时间"`），并在缺失时回退到列序号
  - **Registry侧**：`registry/util.py` 的提取函数通常是“**列名优先 + 列序号兜底**”；并对 file3 存在“Q/T 二选一 tuple”的特殊分支

> 风险：一旦 DataFrame 的列结构（header 是否为 None、是否做过 rename、是否加入新列）发生变化，`iloc` 的列序号映射就容易漂移；而 `window/registry` 又可能在列名不存在时回退序号，导致“看起来跑了但匹配不到/写错列”的隐性问题。

### 8.2 关键业务字段的统一口径（建议标准）

建议明确 5 个“全链路关键字段”的**唯一语义**与**唯一命名**，并规定在哪个边界做转换：

- **`file_type`**
  - **唯一语义**：文件类型编号 1~6（int）
  - **统一建议**：
    - UI/写回/registry 钩子统一用 `int`
    - `.pkl` 结果缓存的命名参数允许继续使用 `'file1'...'file6'`（仅限缓存键/文件名），但**不在业务逻辑里混用**

- **`row_index`（强烈建议统一）**
  - **唯一语义**：Excel 中的 1-based 行号（含表头；数据通常从 2 开始）
  - **统一建议**：
    - DataFrame 内统一存为 `原始行号`（数值），并明确这是 Excel 行号
    - 任何需要写回 Excel / 生成 Registry task_id 的地方，都用该 `row_index`（Excel 行号），禁止用 pandas index 临时推算（`idx+2` 只能作为兜底）

- **`source_file`**
  - **唯一语义**：写回/定位源 Excel 的**绝对路径**
  - **统一建议**：
    - DataFrame 内字段统一为 `source_file`（abs path）
    - Registry 内参与 `task_id` 的 `source_file` 只取 `basename`（当前实现已是这样），但建议同时把绝对路径写入独立字段（若你需要追溯来源盘符/目录）

- **`interface_id`**
  - **唯一语义**：接口号的“业务主键”，**不含角色后缀**
  - **现状观察**：UI 显示里有时会拼接 `(角色来源)`；Registry/util 侧会用正则剥离 `(...)`
  - **统一建议**：
    - DataFrame 内保存 `接口号` 字段时，建议始终为“纯接口号”（clean）
    - 若需要显示角色来源，单独用字段（例如 `角色来源`）渲染 UI，而不是改写接口号字符串

- **`source_column` / `_source_column`（file3 专用）**
  - **唯一语义**：file3 的“回文单号写回列族”来源标记：`'M'` 或 `'L'`
  - **统一建议**：
    - DataFrame 内统一字段名为 `_source_column`（现状已存在）
    - UI 元数据与写回任务 payload 使用字段名 `source_column`（值来自 `_source_column`）
    - 其他文件类型明确为 `None`

### 8.3 已发现的“可能导致未命中/写错”的热点（按风险排序）

- **热点A（高风险）：`main.py` 的 `iloc` 列序号映射与“语义列名”混用**
  - 典型特征：大量 `df.iloc[:, 12]`、`df.iloc[idx, 37]` 等硬编码列号
  - 若未来 Excel 模板列插入/删除，或 `read_excel` 的 `header` 策略调整，很容易让筛选条件错位但不报错
  - 建议：把每个 file_type 的“列规范（语义名→Excel列字母→0-based index）”集中到一个模块，处理侧只引用这份规范

- **热点B（中高风险）：`row_index` 在多处被 `idx+2` 兜底推算**
  - `window.py`、`base.py`、`registry` 侧都存在兜底推算行为
  - 一旦 DataFrame 被过滤/排序/重建 index，`idx+2` 就可能与真实 Excel 行号不一致
  - 建议：强制要求“处理结果 DF 必须包含 `原始行号`”，UI/registry 全链路优先使用它

- **热点C（中风险）：file3 的 “Q/T 二选一” 在 registry/util 与写回映射是两套表达**
  - registry/util 用 `(16, 19)` tuple 表示 Q/T 两列（iloc）
  - 写回用 `input_handler.py` 的列字母映射：`Q/T` 对应的 time_col 会随 `source_column` 改变
  - 建议：把“file3 的 completed/time/response 列族”从 tuple/字母散落定义，统一到同一份 ColumnSpec

- **热点D（中风险）：`interface_id` 角色后缀的清理与显示混用**
  - UI 可能显示 `接口号(角色)`，而 Registry 以 clean id 为主键，依赖“剥离括号”来对齐
  - 建议：把“显示装饰”与“业务主键”彻底分离（字段分离）

### 8.4 建议的“统一策略落地顺序”（不改业务，只做一致性）

1) **建立 ColumnSpec（单一真源）**：为 file1~6 定义：
   - 语义列名（如 `接口号/接口时间/完成列/责任人`）
   - Excel 列字母（用于 openpyxl 写回）
   - 0-based 索引（用于 header=None 的 pandas 读取）
2) **强制行号统一**：处理结果必须产出 `原始行号`；显示/registry 不再用 `idx+2`（只保留极端兜底）
3) **接口号主键统一**：业务全链路使用 clean `interface_id`；UI 角色来源单独字段渲染
4) **file3 source_column 统一**：明确 `_source_column` 的唯一来源与传递路径（DF→UI metadata→write task payload）

---

## 9. 实施记录（按你确认的5步分阶段推进）

> 规则：每完成一步：做对应代码改动 + 跑一个最小 pytest + 更新本文档，然后暂停等待你确认再继续。

### Step1（已完成）：移除预加载 + 移除未处理原始预览（仅“开始处理后显示结果”）

- **改动点**：
  - `base.py::identify_target_files()`：删除“方案3 并发预加载Excel文件”
  - `base.py::on_tab_changed()`：未处理状态不再 `load_file_to_viewer()/display_excel_data()`，统一提示“请点击开始处理生成结果”
- **预期收益**：
  - 刷新文件列表/切换tab 不再触发任何 Excel IO（网络盘卡顿显著下降）
  - 彻底消除“缓存命中但仍发生预读Excel”的冗余
- **对应最小测试**：
  - `tests/test_step1_no_raw_preview_on_tab_change.py`

### Step2（进行中→完成）：start_processing 复用 refresh 阶段内存缓存 + 按 file_path 增量处理

- **改动目标**：
  - 消除“刷新阶段已 load_cached_result → 开始处理阶段又 _process_with_cache 再 load_cached_result 一遍”的重复 IO
  - 在 `start_processing()` 内，对每个项目按 `file_path` 粒度判断是否变化：未变化则优先复用 refresh 阶段已加载到内存的 raw 缓存结果

- **核心实现**：
  - `base.py::_check_and_load_cache()`：在加载 `.pkl` 后，额外保存一份 **raw（角色筛选前）** 到：
    - `self._cache_loaded_raw_multi1..6`
    - 同时记录 `self._cache_loaded_snapshot["all_file_paths"]`
  - `base.py::start_processing()`：
    - 保存 `changed_files_for_run` 与 `all_file_paths_for_run` 供后台线程复用
    - file1~6 的 per-project 循环里：若快照匹配且 `file_path` 未变化，则调用 `_get_refresh_cached_raw_df(...)` 复用内存 raw df；否则继续走 `_process_with_cache(...)`
    - 各 fileX 不再先 `self.processing_results_multiX = {}` 直接清空，而是使用 `new_multiX` 汇总后一次性回写，避免残留旧项目

- **对应最小测试**：
  - `tests/test_step2_refresh_cache_reuse.py`


