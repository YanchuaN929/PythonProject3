## 目标

- 在不破坏现有 find→process→export 流程与界面逻辑的前提下，新增“中心登记簿 + 记录追踪”，解决：
  - 设计人员回填后，上级仍可见并可确认；
  - 非设计角色默认视图不被长期过期项占满（第一步仅记录，第二步再接UI）。
- 所有新增逻辑放入新目录，不改老函数语义；仅在明确位置调用钩子。

## 新增目录与文件

- 新建目录：`registry/`
  - `registry/db.py`：SQLite 连接、建表、WAL 开启、基础CRUD
  - `registry/models.py`：数据模型（Task、Event）与枚举/常量
  - `registry/service.py`：高阶业务：写任务、写事件、缺失检测、归档
  - `registry/hooks.py`：供现有程序调用的统一钩子API（无副作用返回，不抛异常）
  - `registry/config.py`：默认配置读取（复用 `config.json`，键不存在走默认）
  - `registry/util.py`：task_id 生成、字段提取工具（接口号/项目号/文件名等）

## 数据模型（SQLite）

- 表 tasks（任务事实状态）
  - id TEXT PRIMARY KEY（task_id，见下节）
  - file_type INTEGER NOT NULL
  - project_id TEXT NOT NULL  （文件6若缺四位号，保存为“未知项目”以满足非空）
  - interface_id TEXT NOT NULL（统一“接口号”）
  - source_file TEXT NOT NULL  （basename）
  - row_index INTEGER NOT NULL  （Excel原始行号）
  - department TEXT DEFAULT ''
  - interface_time TEXT DEFAULT ''  （mm.dd 或 yyyy.mm.dd）
  - status TEXT NOT NULL DEFAULT 'open'  in ['open','completed','confirmed','archived']
  - completed_at TEXT NULL
  - confirmed_at TEXT NULL
  - first_seen_at TEXT NOT NULL
  - last_seen_at TEXT NOT NULL
  - missing_since TEXT NULL
  - archive_reason TEXT NULL
  - UNIQUE(file_type, project_id, interface_id, source_file, row_index)
  - 索引：file_type+project_id、status、last_seen_at

- 表 events（行为追踪）
  - id INTEGER PRIMARY KEY AUTOINCREMENT
  - ts TEXT NOT NULL
  - event TEXT NOT NULL in ['hit','miss','process_done','export_done','response_written','confirmed','archived','invalidate','clear']
  - file_type INTEGER
  - project_id TEXT
  - interface_id TEXT
  - source_file TEXT
  - row_index INTEGER
  - extra JSON TEXT

- 连接设置：PRAGMA journal_mode=WAL; PRAGMA busy_timeout=5000; PRAGMA synchronous=NORMAL;

## task_id 生成

- 规则：`sha1(f"{file_type}|{project_id}|{interface_id}|{source_file_basename}|{row_index}")`
- 关键字段来源：
  - file_type：1~6（由调用点传入）
  - project_id：取 DataFrame 的“项目号”；若文件6缺四位号，统一写入“未知项目”
  - interface_id：六类统一抽取“接口号”（详见 util）
  - source_file_basename：从处理函数收到的原文件路径取 basename
  - row_index：DataFrame 中“原始行号”

## 钩子API（registry/hooks.py）

- 约定：所有钩子内部 try/except，不向外抛异常；失败仅写日志。
- API 列表与入参：
  - `on_process_done(file_type:int, project_id:str, source_file:str, result_df:pd.DataFrame, now:datetime)`
    - 逐行 upsert tasks：更新 interface_time/department/last_seen_at；首次见到写 first_seen_at
    - 写 event process_done（extra: 行数/项目等）
  - `on_export_done(file_type:int, project_id:str, export_path:str, count:int, now:datetime)`
    - 写 event export_done
  - `on_response_written(file_type:int, file_path:str, row_index:int, response_number:str, user_name:str, project_id:str, source_column:Optional[str], now:datetime)`
    - 定位 task（组合键）；status=open→completed，写 completed_at，写 event response_written
  - `on_confirmed_by_superior(file_type:int, file_path:str, row_index:int, user_name:str, project_id:str, now:datetime)`
    - 任意上级调用；status=completed→confirmed，写 confirmed_at，写 event confirmed
  - `on_scan_finalize(batch_tag:str, now:datetime, missing_keep_days:int=7)`
    - 批次结束调用：标记未出现且未完成的任务 missing_since；超过 N 天自动归档，写 event archived

## 工具函数（registry/util.py）

- `extract_interface_id(df_row:pd.Series, file_type:int) -> str`
  - 按映射取“接口号”所在列（与 window.py/distribution.py 保持一致）：
    - 1:A(0), 2:R(17), 3:C(2), 4:E(4), 5:A(0), 6:E(4)
  - 若已有“接口号”列则优先，否则按索引回退
- `normalize_project_id(pid:str, file_type:int) -> str`
  - 返回 `pid.strip()`；若 file_type==6 且空，返回 “未知项目”
- `get_source_basename(path:str) -> str`
- `safe_now() -> datetime`

## 接入点与插入位置（仅新增调用，不改原逻辑）

- `base.py`
  - 在批量处理内部，处理完每一类并得到 DataFrame 后，立即上报：
    - 文件1：在合并 `self.processing_results_multi1` 之后、进入显示/导出之前：
      - `from registry import hooks`
      - `hooks.on_process_done(1, project_id, file_path, result, self.current_datetime)`
    - 文件2~6：同理，在各类的“有结果则写入 `processing_results_multiX`”之后调用。
  - `export_results()` → do_export 每一类导出完成后：
    - `hooks.on_export_done(file_type, project_id, output_path, len(df), self.current_datetime)`
  - 一次完整扫描后（所有类型识别与处理均结束）：
    - 在本轮处理线程回调的末尾（与 Monitor/弹窗之后），调用：
      - `hooks.on_scan_finalize(batch_tag, self.current_datetime, missing_keep_days=7)`
      - `batch_tag = self.current_datetime.strftime('%Y%m%d%H%M%S')`

- `input_handler.py`
  - `write_response_to_excel` 成功保存后（return True 前）调用：
    - `from registry import hooks`
    - `hooks.on_response_written(file_type, file_path, row_index, response_number, user_name, project_id, source_column, now=safe_now())`

- `distribution.py`（可选）
  - `save_assignment` 成功后记一条 `assigned` 事件（不改任务状态）：
    - `hooks.write_event('assigned', file_type, project_id, interface_id, file_path, row_index, extra={'assignee': assigned_name})`

- `window.py`、`main2.py`：第一步不变；第二步再加“确认/历史”UI。

## 配置（registry/config.py）

- 新增键（若缺用默认值）：
  - `registry_enabled`（bool，默认 True）
  - `registry_db_path`（字符串，默认 `result_cache/registry.db` 或公共盘路径）
  - `registry_missing_keep_days`（int，默认7）
  - `registry_wal`（bool，默认 True）
- hooks 首行检查 `registry_enabled`，关闭则直接 return。

## 并发与性能

- SQLite WAL + busy_timeout；单进程内共享连接 + 线程锁；批量写 process_done 时用事务。

## 迁移与初始化

- 首次运行自动建库建表；不做历史补录。
- 文件6项目号空值一律存“未知项目”。

## 验收点

- 回文单号写入后，tasks.status=completed；上级确认后变 confirmed。
- 周更缺失：tasks.missing_since 标记；超过 7 天自动归档；events 记录完整。

---

## 新增文件骨架（函数签名 + 空实现）

> 说明：以下为最小可读骨架，另一个AI据此补全实现即可。

```python
# registry/config.py
import json
import os

DEFAULTS = {
    "registry_enabled": True,
    "registry_db_path": os.path.join("result_cache", "registry.db"),
    "registry_missing_keep_days": 7,
    "registry_wal": True,
}

def load_config(config_path: str = "config.json") -> dict:
    try:
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                data = json.load(f) or {}
        else:
            data = {}
    except Exception:
        data = {}
    # 平铺获取，缺失走默认
    cfg = DEFAULTS.copy()
    for k in DEFAULTS:
        if k in data:
            cfg[k] = data[k]
    return cfg
```

```python
# registry/db.py
import os
import sqlite3
from typing import Optional

_CONN: Optional[sqlite3.Connection] = None

def get_connection(db_path: str, wal: bool = True) -> sqlite3.Connection:
    global _CONN
    if _CONN is not None:
        return _CONN
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    conn = sqlite3.connect(db_path, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    if wal:
        try:
            conn.execute("PRAGMA journal_mode=WAL;")
        except Exception:
            pass
    try:
        conn.execute("PRAGMA busy_timeout=5000;")
        conn.execute("PRAGMA synchronous=NORMAL;")
    except Exception:
        pass
    init_db(conn)
    _CONN = conn
    return conn

def init_db(conn: sqlite3.Connection) -> None:
    cur = conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS tasks (
            id TEXT PRIMARY KEY,
            file_type INTEGER NOT NULL,
            project_id TEXT NOT NULL,
            interface_id TEXT NOT NULL,
            source_file TEXT NOT NULL,
            row_index INTEGER NOT NULL,
            department TEXT DEFAULT '',
            interface_time TEXT DEFAULT '',
            status TEXT NOT NULL DEFAULT 'open',
            completed_at TEXT NULL,
            confirmed_at TEXT NULL,
            first_seen_at TEXT NOT NULL,
            last_seen_at TEXT NOT NULL,
            missing_since TEXT NULL,
            archive_reason TEXT NULL,
            UNIQUE(file_type, project_id, interface_id, source_file, row_index)
        );
        """
    )
    cur.execute("CREATE INDEX IF NOT EXISTS idx_tasks_ft_pid ON tasks(file_type, project_id);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_tasks_last_seen ON tasks(last_seen_at);")
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts TEXT NOT NULL,
            event TEXT NOT NULL,
            file_type INTEGER,
            project_id TEXT,
            interface_id TEXT,
            source_file TEXT,
            row_index INTEGER,
            extra TEXT
        );
        """
    )
    conn.commit()
```

```python
# registry/models.py
from dataclasses import dataclass

class Status:
    OPEN = "open"
    COMPLETED = "completed"
    CONFIRMED = "confirmed"
    ARCHIVED = "archived"

class EventType:
    PROCESS_DONE = "process_done"
    EXPORT_DONE = "export_done"
    RESPONSE_WRITTEN = "response_written"
    CONFIRMED = "confirmed"
    ARCHIVED = "archived"
    ASSIGNED = "assigned"

@dataclass
class TaskKey:
    file_type: int
    project_id: str
    interface_id: str
    source_file: str
    row_index: int
```

```python
# registry/util.py
import hashlib
import os
from datetime import datetime

def get_source_basename(path: str) -> str:
    try:
        return os.path.basename(path or "")
    except Exception:
        return ""

def normalize_project_id(pid: str, file_type: int) -> str:
    s = (pid or "").strip()
    if file_type == 6 and not s:
        return "未知项目"
    return s

def extract_interface_id(row, file_type: int) -> str:
    try:
        # 优先列名
        if hasattr(row, 'get') and '接口号' in row.index:
            v = row.get('接口号')
            return str(v).strip() if v is not None else ""
        # 回退索引映射
        idx_map = {1:0, 2:17, 3:2, 4:4, 5:0, 6:4}
        idx = idx_map.get(file_type, 0)
        if idx < len(row):
            v = row.iloc[idx]
            return str(v).strip() if v is not None else ""
        return ""
    except Exception:
        return ""

def make_task_id(file_type: int, project_id: str, interface_id: str, source_file: str, row_index: int) -> str:
    raw = f"{file_type}|{project_id}|{interface_id}|{source_file}|{row_index}"
    return hashlib.sha1(raw.encode('utf-8')).hexdigest()

def safe_now() -> datetime:
    return datetime.utcnow()
```

```python
# registry/service.py
from typing import Optional, Dict, Any
from datetime import datetime
import json
from .db import get_connection
from .models import Status, EventType
from .util import make_task_id

def upsert_task(db_path: str, wal: bool, key: Dict[str, Any], fields: Dict[str, Any], now: datetime) -> None:
    """按唯一键(file_type, project_id, interface_id, source_file, row_index) upsert 任务。"""
    conn = get_connection(db_path, wal)
    tid = make_task_id(key['file_type'], key['project_id'], key['interface_id'], key['source_file'], key['row_index'])
    conn.execute(
        """
        INSERT INTO tasks (id, file_type, project_id, interface_id, source_file, row_index, department, interface_time, status, first_seen_at, last_seen_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ON CONFLICT(id) DO UPDATE SET
          department=excluded.department,
          interface_time=excluded.interface_time,
          last_seen_at=excluded.last_seen_at
        """,
        (
            tid,
            key['file_type'], key['project_id'], key['interface_id'], key['source_file'], key['row_index'],
            fields.get('department', ''), fields.get('interface_time', ''), fields.get('status', Status.OPEN),
            now.isoformat(), now.isoformat()
        )
    )
    conn.commit()

def write_event(db_path: str, wal: bool, event: str, payload: Dict[str, Any], now: datetime) -> None:
    conn = get_connection(db_path, wal)
    conn.execute(
        "INSERT INTO events (ts, event, file_type, project_id, interface_id, source_file, row_index, extra) VALUES (?,?,?,?,?,?,?,?)",
        (
            now.isoformat(), event,
            payload.get('file_type'), payload.get('project_id'), payload.get('interface_id'),
            payload.get('source_file'), payload.get('row_index'), json.dumps(payload.get('extra') or {})
        )
    )
    conn.commit()

def mark_completed(db_path: str, wal: bool, key: Dict[str, Any], now: datetime) -> None:
    conn = get_connection(db_path, wal)
    tid = make_task_id(key['file_type'], key['project_id'], key['interface_id'], key['source_file'], key['row_index'])
    conn.execute("UPDATE tasks SET status=?, completed_at=? WHERE id=?", (Status.COMPLETED, now.isoformat(), tid))
    conn.commit()

def mark_confirmed(db_path: str, wal: bool, key: Dict[str, Any], now: datetime) -> None:
    conn = get_connection(db_path, wal)
    tid = make_task_id(key['file_type'], key['project_id'], key['interface_id'], key['source_file'], key['row_index'])
    conn.execute("UPDATE tasks SET status=?, confirmed_at=? WHERE id=?", (Status.CONFIRMED, now.isoformat(), tid))
    conn.commit()

def finalize_scan(db_path: str, wal: bool, now: datetime, missing_keep_days: int) -> None:
    """标记缺失并对超期 missing 进行归档（missing_from_source）。"""
    # 骨架：由另一个AI补充基于 last_seen_at/missing_since 的计算与归档
    pass
```

```python
# registry/hooks.py
from typing import Optional
from datetime import datetime
import pandas as pd
from .config import load_config
from .service import upsert_task, write_event, mark_completed, mark_confirmed, finalize_scan
from .models import EventType, Status
from .util import extract_interface_id, normalize_project_id, get_source_basename, safe_now

def _cfg():
    return load_config()

def _enabled(cfg: dict) -> bool:
    return bool(cfg.get('registry_enabled', True))

def on_process_done(file_type: int, project_id: str, source_file: str, result_df: pd.DataFrame, now: Optional[datetime] = None) -> None:
    try:
        cfg = _cfg()
        if not _enabled(cfg):
            return
        now = now or safe_now()
        db_path = cfg['registry_db_path']; wal = bool(cfg.get('registry_wal', True))
        basename = get_source_basename(source_file)
        # 行级 upsert
        for _, row in (result_df or pd.DataFrame()).iterrows():
            pid = normalize_project_id(str(row.get('项目号', project_id)), file_type)
            iid = extract_interface_id(row, file_type)
            if not iid:
                continue
            key = {
                'file_type': file_type,
                'project_id': pid,
                'interface_id': iid,
                'source_file': basename,
                'row_index': int(row.get('原始行号', 0) or 0),
            }
            fields = {
                'department': str(row.get('科室', '') or ''),
                'interface_time': str(row.get('接口时间', '') or ''),
                'status': Status.OPEN,
            }
            upsert_task(db_path, wal, key, fields, now)
        write_event(db_path, wal, EventType.PROCESS_DONE, {
            'file_type': file_type, 'project_id': project_id, 'source_file': basename,
            'extra': {'rows': int(len(result_df) if result_df is not None else 0)}
        }, now)
    except Exception:
        pass

def on_export_done(file_type: int, project_id: str, export_path: str, count: int, now: Optional[datetime] = None) -> None:
    try:
        cfg = _cfg()
        if not _enabled(cfg):
            return
        now = now or safe_now()
        db_path = cfg['registry_db_path']; wal = bool(cfg.get('registry_wal', True))
        write_event(db_path, wal, EventType.EXPORT_DONE, {
            'file_type': file_type, 'project_id': project_id,
            'source_file': get_source_basename(export_path), 'extra': {'count': int(count)}
        }, now)
    except Exception:
        pass

def on_response_written(file_type: int, file_path: str, row_index: int, response_number: str, user_name: str, project_id: str, source_column: Optional[str] = None, now: Optional[datetime] = None) -> None:
    try:
        cfg = _cfg()
        if not _enabled(cfg):
            return
        now = now or safe_now()
        db_path = cfg['registry_db_path']; wal = bool(cfg.get('registry_wal', True))
        key = {
            'file_type': file_type,
            'project_id': normalize_project_id(project_id, file_type),
            'interface_id': "",  # 由另一个AI在实现时通过读取该行数据补齐或用已缓存接口号
            'source_file': get_source_basename(file_path),
            'row_index': int(row_index or 0),
        }
        # 注：上面 interface_id 可在完善实现时二次读取该行接口号补齐
        mark_completed(db_path, wal, key, now)
        write_event(db_path, wal, EventType.RESPONSE_WRITTEN, {
            'file_type': file_type, 'project_id': key['project_id'], 'source_file': key['source_file'], 'row_index': key['row_index'],
            'extra': {'response_number': response_number, 'user_name': user_name, 'source_column': source_column}
        }, now)
    except Exception:
        pass

def on_confirmed_by_superior(file_type: int, file_path: str, row_index: int, user_name: str, project_id: str, now: Optional[datetime] = None) -> None:
    try:
        cfg = _cfg()
        if not _enabled(cfg):
            return
        now = now or safe_now()
        db_path = cfg['registry_db_path']; wal = bool(cfg.get('registry_wal', True))
        key = {
            'file_type': file_type,
            'project_id': normalize_project_id(project_id, file_type),
            'interface_id': "",  # 同上：完善实现时补齐
            'source_file': get_source_basename(file_path),
            'row_index': int(row_index or 0),
        }
        mark_confirmed(db_path, wal, key, now)
        write_event(db_path, wal, EventType.CONFIRMED, {
            'file_type': file_type, 'project_id': key['project_id'], 'source_file': key['source_file'], 'row_index': key['row_index'],
            'extra': {'user_name': user_name}
        }, now)
    except Exception:
        pass

def on_scan_finalize(batch_tag: str, now: Optional[datetime] = None, missing_keep_days: Optional[int] = None) -> None:
    try:
        cfg = _cfg()
        if not _enabled(cfg):
            return
        now = now or safe_now()
        db_path = cfg['registry_db_path']; wal = bool(cfg.get('registry_wal', True))
        days = int(missing_keep_days if missing_keep_days is not None else int(cfg.get('registry_missing_keep_days', 7)))
        finalize_scan(db_path, wal, now, days)
    except Exception:
        pass

def write_event_only(event: str, payload: dict) -> None:
    try:
        cfg = _cfg()
        if not _enabled(cfg):
            return
        db_path = cfg['registry_db_path']; wal = bool(cfg.get('registry_wal', True))
        write_event(db_path, wal, event, payload, safe_now())
    except Exception:
        pass
```

---

## 另一AI的执行顺序（分步清单）

1) 创建目录 `registry/` 并新增 6 个文件：`db.py` `models.py` `service.py` `hooks.py` `config.py` `util.py`；粘贴上述骨架。
2) 在 `base.py` 的批量处理处（每一类合并 `processing_results_multiX` 后）增调用：`hooks.on_process_done(...)`。
3) 在 `base.py` 的 `export_results()` 中每个导出完成后增：`hooks.on_export_done(...)`。
4) 在处理线程结束（所有类别处理后）调用：`hooks.on_scan_finalize(batch_tag, now)`。
5) 在 `input_handler.write_response_to_excel` 成功返回 True 前增：`hooks.on_response_written(...)`。
6) 可选：`distribution.save_assignment` 成功后写一个 `assigned` 事件（`hooks.write_event_only(...)`）。
7) 若需要，将 `registry_db_path` 指向公共盘共享路径；否则默认使用 `result_cache/registry.db`。


