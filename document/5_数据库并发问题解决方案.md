# 数据库并发问题解决方案

## ✅ 已修复（2024年12月）

### 问题现象
在多用户环境下使用程序时，**几乎所有第二个及之后登录的用户**都会遇到以下错误：

```
数据库连接失败
数据库操作失败: 数据库被其他用户锁定，请稍后重试
```

### 根本原因：WAL模式独占锁

**问题核心**：程序使用了 SQLite 的 WAL（Write-Ahead Logging）模式，该模式会创建两个辅助文件：
- `registry.db-shm`（共享内存文件）
- `registry.db-wal`（预写日志文件）

**在网络盘上的致命问题**：
1. WAL 模式需要对 `-shm` 文件进行内存映射（mmap）
2. 在网络文件系统（SMB/CIFS）上，内存映射会变成**进程级独占锁**
3. 第一个用户的程序启动后锁定 `-shm` 文件
4. 只要第一个用户的程序还在运行，所有其他用户都无法访问数据库！

### 修复方案

**核心修改**：在网络路径上自动禁用 WAL 模式

```python
# registry/db.py

def _is_network_path(path: str) -> bool:
    """检测路径是否为网络路径（UNC路径或映射的网络驱动器）"""
    # UNC 路径 (\\server\share)
    if path.startswith('\\\\') or path.startswith('//'):
        return True
    # 检查映射的网络驱动器
    ...

def get_connection(db_path: str, wal: bool = True) -> sqlite3.Connection:
    # 网络路径自动禁用WAL模式
    is_network = _is_network_path(db_path)
    if is_network and wal:
        print("[Registry] 检测到网络路径，自动禁用WAL模式")
        wal = False
        _cleanup_wal_files(db_path)  # 清理旧的WAL文件
    
    # 使用DELETE模式代替WAL模式
    if wal:
        conn.execute("PRAGMA journal_mode=WAL")
    else:
        conn.execute("PRAGMA journal_mode=DELETE")
```

**同时增加超时时间**：
- 连接超时：60秒（原30秒）
- 繁忙超时：30秒（原5秒）

### 测试验证

新增 16 个测试用例（`tests/test_db_network_path.py`）：
- UNC路径检测（7个）
- WAL文件清理（3个）
- 网络路径连接模式（3个）
- 连接单例管理（2个）
- 数据库初始化（1个）

---

## 问题背景（历史记录）

### 技术分析

| 问题点 | 说明 | 状态 |
|--------|------|------|
| WAL模式 | WAL 模式需要 `-shm` 文件的内存映射，在网络盘上导致独占锁 | ✅ 已修复 |
| 文件锁机制 | SQLite 依赖操作系统的文件锁，网络文件系统的锁实现不可靠 | ⚠️ 需观察 |
| 并发写入 | 多用户同时写入时，锁竞争激烈，容易超时 | ⚠️ 已优化超时 |

---

## 备选方案（如仍有问题可考虑）

| 方案 | 改动量 | 效果 | 复杂度 | 推荐指数 |
|------|--------|------|--------|----------|
| 方案A：读写分离+智能重试 | 小 | 覆盖90%场景 | 低 | ⭐⭐⭐⭐⭐ |
| 方案B：本地优先+网络同步 | 大 | 彻底解决 | 高 | ⭐⭐⭐ |
| 方案C：服务端数据库 | 中 | 彻底解决 | 中（需基础设施） | ⭐⭐⭐⭐ |

---

## 方案A：读写分离 + 智能重试（推荐）

### 核心思路

读取操作几乎不会造成锁定，问题主要出在写入操作。通过优化读写策略和添加智能重试机制，可以覆盖绑bindbindbindbindbindingbindingindbindind大多数使用场景。

### 实现细节

#### 1. 读取操作优化

**当前问题**：所有操作使用同一个连接，读取时也可能触发锁等待。

**优化方案**：读取操作使用只读模式连接

```python
# 只读连接（不获取写锁）
def get_readonly_connection(db_path: str) -> sqlite3.Connection:
    """获取只读数据库连接"""
    uri = f"file:{db_path}?mode=ro"
    conn = sqlite3.connect(uri, uri=True, check_same_thread=False, timeout=10.0)
    return conn
```

**效果**：
- 读取操作不会阻塞写入操作
- 多个用户可以同时读取
- 只有写入操作之间才会竞争锁

#### 2. 写入操作智能重试

**当前问题**：`busy_timeout=5000`（5秒），超时后直接报错。

**优化方案**：实现带指数退避的智能重试

```python
def execute_with_retry(conn, sql, params=None, max_retries=3, base_delay=1.0):
    """
    带重试的SQL执行
    
    重试策略：
    - 第1次失败：等待1秒后重试
    - 第2次失败：等待2秒后重试
    - 第3次失败：等待4秒后重试
    - 超过最大重试次数：抛出异常
    """
    for attempt in range(max_retries + 1):
        try:
            cursor = conn.execute(sql, params or ())
            conn.commit()
            return cursor
        except sqlite3.OperationalError as e:
            if "database is locked" in str(e).lower():
                if attempt < max_retries:
                    delay = base_delay * (2 ** attempt)  # 指数退避
                    print(f"[数据库] 锁定中，{delay}秒后重试 ({attempt+1}/{max_retries})")
                    time.sleep(delay)
                else:
                    raise
            else:
                raise
```

#### 3. 批量写入优化

**当前问题**：刷新数据时一次性批量写入所有任务，长时间持有锁。

**优化方案**：分批写入 + 进度提示

```python
def batch_upsert_with_progress(tasks_data, batch_size=50):
    """
    分批写入任务数据
    
    - 每批50条，写完释放锁
    - 显示进度，让用户知道正在处理
    - 批次间短暂等待，给其他用户操作机会
    """
    total = len(tasks_data)
    for i in range(0, total, batch_size):
        batch = tasks_data[i:i+batch_size]
        # 写入当前批次
        _do_batch_insert(batch)
        # 显示进度
        progress = min(i + batch_size, total)
        print(f"[数据库] 写入进度: {progress}/{total}")
        # 短暂等待，给其他用户机会
        if i + batch_size < total:
            time.sleep(0.1)
```

#### 4. 用户友好提示

**当前问题**：直接弹出错误对话框，用户不知道发生了什么。

**优化方案**：等待时显示进度提示

```python
def show_waiting_dialog(parent, message="正在等待其他用户操作完成..."):
    """显示等待对话框"""
    dialog = tk.Toplevel(parent)
    dialog.title("请稍候")
    ttk.Label(dialog, text=message).pack(padx=20, pady=20)
    ttk.Progressbar(dialog, mode='indeterminate').pack(padx=20, pady=10)
    return dialog
```

### 需要修改的文件

| 文件 | 修改内容 |
|------|----------|
| `registry/db.py` | 添加只读连接函数、重试机制 |
| `registry/service.py` | 读取操作使用只读连接，写入操作添加重试 |
| `registry/hooks.py` | 批量写入改为分批处理 |

### 优点

- ✅ 改动量小，风险低
- ✅ 向后兼容，不改变数据结构
- ✅ 覆盖90%以上的使用场景
- ✅ 用户体验改善（有等待提示而非直接报错）

### 缺点

- ❌ 不能彻底解决问题，极端并发场景仍可能失败
- ❌ 高并发写入时，后续用户需要等待

### 适用场景

- 用户数量 < 20人
- 操作频率不高（每人每天操作几十次）
- 对实时性要求不高（可以接受几秒延迟）

---

## 方案B：本地优先 + 网络同步

### 核心思路

每个用户在本地维护一个数据库副本，操作时先写本地（即时响应），后台异步同步到网络共享数据库。

### 架构设计

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   用户A本地      │     │   用户B本地      │     │   用户C本地      │
│   local_A.db    │     │   local_B.db    │     │   local_C.db    │
└────────┬────────┘     └────────┬────────┘     └────────┬────────┘
         │                       │                       │
         │     后台异步同步       │                       │
         ▼                       ▼                       ▼
┌─────────────────────────────────────────────────────────────────┐
│                    网络共享数据库                                 │
│            //server/share/.registry/registry.db                 │
└─────────────────────────────────────────────────────────────────┘
```

### 实现细节

#### 1. 本地数据库管理

```python
class LocalDbManager:
    """本地数据库管理器"""
    
    def __init__(self, user_name: str):
        # 本地数据库路径：%APPDATA%/ExcelProcessor/local.db
        self.local_db = os.path.join(
            os.environ.get('APPDATA', '.'),
            'ExcelProcessor',
            f'local_{user_name}.db'
        )
        self.network_db = None  # 网络数据库路径
        
    def write(self, task_id, data):
        """写入操作：先写本地"""
        # 1. 立即写入本地数据库
        self._write_local(task_id, data)
        # 2. 标记为待同步
        self._mark_pending_sync(task_id)
        # 3. 触发后台同步（不阻塞）
        self._trigger_background_sync()
        
    def read(self, task_id):
        """读取操作：合并本地和网络数据"""
        local_data = self._read_local(task_id)
        network_data = self._read_network(task_id)
        return self._merge_data(local_data, network_data)
```

#### 2. 后台同步机制

```python
class BackgroundSyncer:
    """后台同步器"""
    
    def __init__(self, local_db, network_db):
        self.local_db = local_db
        self.network_db = network_db
        self.sync_queue = queue.Queue()
        self.sync_thread = threading.Thread(target=self._sync_worker, daemon=True)
        self.sync_thread.start()
        
    def _sync_worker(self):
        """同步工作线程"""
        while True:
            try:
                task_id = self.sync_queue.get(timeout=5.0)
                self._do_sync(task_id)
            except queue.Empty:
                # 定期检查是否有待同步数据
                self._sync_all_pending()
                
    def _do_sync(self, task_id):
        """执行单个任务的同步"""
        local_data = self._get_local(task_id)
        try:
            self._write_network(task_id, local_data)
            self._mark_synced(task_id)
        except sqlite3.OperationalError:
            # 网络数据库锁定，稍后重试
            self.sync_queue.put(task_id)
            time.sleep(1.0)
```

#### 3. 冲突解决策略

当两个用户同时修改同一条记录时：

```python
def resolve_conflict(local_data, network_data):
    """
    冲突解决策略：最后修改者获胜
    
    比较 modified_at 时间戳，保留较新的数据
    """
    local_time = parse_datetime(local_data.get('modified_at'))
    network_time = parse_datetime(network_data.get('modified_at'))
    
    if local_time >= network_time:
        return local_data  # 本地数据较新
    else:
        return network_data  # 网络数据较新
```

### 需要修改的文件

| 文件 | 修改内容 |
|------|----------|
| `registry/db.py` | 重构为支持本地+网络双数据库 |
| `registry/service.py` | 所有读写操作改为通过LocalDbManager |
| `registry/sync.py` | 新增：后台同步模块 |
| `registry/conflict.py` | 新增：冲突解决模块 |
| `base.py` | 初始化时创建本地数据库 |

### 优点

- ✅ 用户操作即时响应（写本地）
- ✅ 网络问题不影响本地操作
- ✅ 彻底解决锁定问题

### 缺点

- ❌ 实现复杂，开发周期长
- ❌ 需要处理数据冲突
- ❌ 数据一致性有延迟（用户A的操作，用户B可能几秒后才看到）
- ❌ 需要管理多个数据库文件
- ❌ 调试和排错更困难

### 适用场景

- 对实时性要求不高
- 可以接受"最终一致性"
- 有足够的开发时间进行实现和测试

---

## 方案C：服务端数据库

### 核心思路

放弃 SQLite，改用真正的客户端-服务器架构数据库（如 MySQL、PostgreSQL），彻底解决并发问题。

### 架构设计

```
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│   用户A     │  │   用户B     │  │   用户C     │
│   客户端    │  │   客户端    │  │   客户端    │
└──────┬──────┘  └──────┬──────┘  └──────┬──────┘
       │               │               │
       │    TCP/IP 连接（3306端口）     │
       ▼               ▼               ▼
┌─────────────────────────────────────────────────┐
│              MySQL/PostgreSQL 服务器             │
│                                                 │
│  ┌─────────────────────────────────────────┐   │
│  │          registry 数据库                 │   │
│  │  - tasks 表                             │   │
│  │  - events 表                            │   │
│  │  - ignored_snapshots 表                 │   │
│  └─────────────────────────────────────────┘   │
│                                                 │
│  特性：                                         │
│  - 行级锁（非文件锁）                           │
│  - 连接池管理                                   │
│  - 事务隔离                                     │
│  - 高并发支持                                   │
└─────────────────────────────────────────────────┘
```

### 实现细节

#### 1. 数据库服务器部署

**选项A：使用现有MySQL服务器**

如果公司已有 MySQL 服务器，可以直接申请创建一个新数据库。

**选项B：部署专用服务器**

```bash
# Docker 快速部署 MySQL
docker run -d \
  --name excel-processor-db \
  -e MYSQL_ROOT_PASSWORD=your_password \
  -e MYSQL_DATABASE=registry \
  -p 3306:3306 \
  mysql:8.0
```

#### 2. 代码改造

**依赖变更**：

```txt
# requirements.txt 新增
PyMySQL==1.0.2  # 或 mysql-connector-python
# 或 PostgreSQL
psycopg2-binary==2.9.5
```

**连接管理**：

```python
# registry/db_mysql.py
import pymysql
from contextlib import contextmanager

# 数据库配置
DB_CONFIG = {
    'host': '10.102.2.7',  # 或专用数据库服务器IP
    'port': 3306,
    'user': 'excel_processor',
    'password': 'your_password',
    'database': 'registry',
    'charset': 'utf8mb4',
    'autocommit': True,
}

@contextmanager
def get_connection():
    """获取数据库连接（连接池）"""
    conn = pymysql.connect(**DB_CONFIG)
    try:
        yield conn
    finally:
        conn.close()

def execute_query(sql, params=None):
    """执行查询"""
    with get_connection() as conn:
        with conn.cursor(pymysql.cursors.DictCursor) as cursor:
            cursor.execute(sql, params or ())
            return cursor.fetchall()

def execute_update(sql, params=None):
    """执行更新"""
    with get_connection() as conn:
        with conn.cursor() as cursor:
            cursor.execute(sql, params or ())
            conn.commit()
            return cursor.rowcount
```

#### 3. SQL语法适配

SQLite 和 MySQL 语法差异需要处理：

```python
# SQLite 语法
sql_sqlite = """
    INSERT OR REPLACE INTO tasks (id, status) VALUES (?, ?)
"""

# MySQL 语法
sql_mysql = """
    INSERT INTO tasks (id, status) VALUES (%s, %s)
    ON DUPLICATE KEY UPDATE status = VALUES(status)
"""
```

### 需要修改的文件

| 文件 | 修改内容 |
|------|----------|
| `registry/db.py` | 替换为 MySQL/PostgreSQL 连接逻辑 |
| `registry/service.py` | SQL语法适配（? → %s，ON CONFLICT → ON DUPLICATE KEY） |
| `registry/migrate.py` | 数据迁移脚本（SQLite → MySQL） |
| `requirements.txt` | 添加 PyMySQL 或 psycopg2 依赖 |
| `config.json` | 添加数据库服务器配置 |

### 数据迁移

```python
# scripts/migrate_to_mysql.py
def migrate_sqlite_to_mysql():
    """将SQLite数据迁移到MySQL"""
    # 1. 连接SQLite
    sqlite_conn = sqlite3.connect('registry.db')
    
    # 2. 连接MySQL
    mysql_conn = pymysql.connect(**DB_CONFIG)
    
    # 3. 迁移tasks表
    sqlite_cur = sqlite_conn.execute("SELECT * FROM tasks")
    rows = sqlite_cur.fetchall()
    
    mysql_cur = mysql_conn.cursor()
    for row in rows:
        mysql_cur.execute(
            "INSERT INTO tasks (...) VALUES (...)",
            row
        )
    mysql_conn.commit()
    
    print(f"迁移完成：{len(rows)} 条记录")
```

### 优点

- ✅ 彻底解决并发问题（数据库层面保证）
- ✅ 支持高并发（100+用户无压力）
- ✅ 行级锁，不同任务的操作互不阻塞
- ✅ 专业的事务支持和数据一致性保证
- ✅ 更好的备份和恢复机制

### 缺点

- ❌ 需要部署和维护数据库服务器
- ❌ 需要网络连接到数据库服务器
- ❌ 增加了系统依赖和复杂度
- ❌ 需要进行代码改造和SQL适配
- ❌ 需要进行数据迁移

### 适用场景

- 用户数量 > 20人
- 对数据一致性要求高
- 有IT基础设施支持
- 未来可能扩展更多功能

---

## 决策建议

### 短期解决（1-2天）

**推荐方案A**：读写分离 + 智能重试

- 最小改动，快速见效
- 覆盖绑定绑定ing大多数使用场景
- 风险低

### 中期优化（1-2周）

如果方案A效果不理想，考虑：

1. **方案C**（如果有数据库服务器资源）
2. **方案B**（如果没有服务器资源）

### 长期规划

如果用户量持续增长或功能持续扩展，建议最终迁移到 **方案C（服务端数据库）**。

---

## 附录：配置参数参考

### 方案A 相关配置

```json
{
    "registry_wal": false,
    "registry_busy_timeout": 30000,
    "registry_retry_count": 3,
    "registry_retry_delay": 1.0,
    "registry_batch_size": 50
}
```

### 方案C 相关配置

```json
{
    "registry_db_type": "mysql",
    "registry_db_host": "10.102.2.7",
    "registry_db_port": 3306,
    "registry_db_user": "excel_processor",
    "registry_db_password": "your_password",
    "registry_db_name": "registry"
}
```

---

## 更新记录

| 日期 | 版本 | 说明 |
|------|------|------|
| 2025-12-01 | 1.0 | 初版，三种方案详细说明 |

